{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script takes in an unput csv with lecture id and text as an input and then uses wikifier to get the annotations for\n",
    "each topic\n",
    "\"\"\"\n",
    "import ujson as json\n",
    "from os import listdir\n",
    "from os.path import isfile, join, basename\n",
    "import requests\n",
    "\n",
    "import time\n",
    "from lib.api import get_wikifier_wikify_response\n",
    "from lib.text import segment_sentences\n",
    "from transcript_reader.utils import ENGLISH_FILE_REGEX\n",
    "\n",
    "_WIKIFIER_URL_PREFIX = \"https://en.wikipedia.org/wiki/\"\n",
    "\n",
    "_WIKIFIER_WIKIFY_URL = u\"http://www.wikifier.org/annotate-article\"\n",
    "\n",
    "CHUNK_SIZE = 15000\n",
    "BULK_SIZE = 50\n",
    "\n",
    "DF_IGNORE_VAL = 50\n",
    "WORDS_IGNORE_VAL = 50\n",
    "\n",
    "ACCURACY_FIELD = u'rho'\n",
    "TITLE_FIELD = u'title'\n",
    "COSINE_FIELD = u'cosine'\n",
    "PAGERANK_FIELD = u'pageRank'\n",
    "WIKI_DATA_ID_FIELD = u'wikiDataItemId'\n",
    "URL_FIELD = u'url'\n",
    "\n",
    "STATUS_FIELD = u'status'\n",
    "ANNOTATION_DATA_FIELD = u'annotation_data'\n",
    "\n",
    "SENTENCE_AGGREGATOR = \" \"\n",
    "LEN_SENTENCE_AGGR = len(SENTENCE_AGGREGATOR)\n",
    "\n",
    "SILENCE_INDICATORS = [\"~silence~\", \"~SILENCE~\", \"~SIL\", \"[SILENCE]\"]\n",
    "HESITATION_INDICATORS = [\"[hesitation]\", \"[HESITATION]\"]\n",
    "UNKNOWN_INDICATORS = [\"<unk>\", \"[UNKNOWN]\", \"[unknown]\"]\n",
    "\n",
    "SPECIAL_TOKENS = set(SILENCE_INDICATORS + HESITATION_INDICATORS + UNKNOWN_INDICATORS)\n",
    "\n",
    "FILEPATH_FIELD = \"filepath\"\n",
    "FILENAME_FIELD = \"filename\"\n",
    "SLUG_FIELD = \"slug\"\n",
    "TEXT_FIELD = \"text\"\n",
    "\n",
    "COLS = [FILEPATH_FIELD, SLUG_FIELD, TEXT_FIELD]\n",
    "\n",
    "ERROR_KEY = u'error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to clean text\n",
    "def get_clean_text(text):\n",
    "    for substr in SPECIAL_TOKENS:\n",
    "        text = text.replace(substr, \"\")\n",
    "    return text\n",
    "\n",
    "# Function to get concepts from the Wikifier response\n",
    "def get_wikififier_concepts(resp, prob=0.0, top_n=None):\n",
    "    annotations = list(sorted([{TITLE_FIELD: ann[TITLE_FIELD],\n",
    "                                URL_FIELD: ann[URL_FIELD],\n",
    "                                COSINE_FIELD: ann[COSINE_FIELD],\n",
    "                                PAGERANK_FIELD: ann[PAGERANK_FIELD],\n",
    "                                WIKI_DATA_ID_FIELD: ann.get(WIKI_DATA_ID_FIELD)}\n",
    "                               for ann in resp.get(\"annotations\", [])],\n",
    "                              key=lambda record: record[PAGERANK_FIELD], reverse=True))\n",
    "\n",
    "    if top_n is not None:\n",
    "        annotations = list(annotations)[:top_n]\n",
    "\n",
    "    return {\n",
    "        ANNOTATION_DATA_FIELD: annotations,\n",
    "        STATUS_FIELD: resp[STATUS_FIELD]\n",
    "    }\n",
    "\n",
    "# Function to call the Wikifier API\n",
    "def get_wikifier_wikify_response(text, api_key, df_ignore, words_ignore):\n",
    "    params = {\n",
    "        \"text\": text,\n",
    "        \"userKey\": api_key,\n",
    "        \"nTopDfValuesToIgnore\": df_ignore,\n",
    "        \"nWordsToIgnoreFromList\": words_ignore\n",
    "    }\n",
    "    r = requests.post(_WIKIFIER_WIKIFY_URL, params)\n",
    "    if r.status_code == 200:\n",
    "        resp = json.loads(r.content)\n",
    "        if ERROR_KEY in resp:\n",
    "            raise ValueError(\"error in response : {}\".format(resp[ERROR_KEY]))\n",
    "        return resp\n",
    "    else:\n",
    "        raise ValueError(\"http status code 200 expected, got status code {} instead\".format(r.status_code))\n",
    "\n",
    "# Function to wikify a single text\n",
    "def _wikify(text, key, df_ignore, words_ignore):\n",
    "    try:\n",
    "        resp = get_wikifier_wikify_response(text, key, df_ignore, words_ignore)\n",
    "        resp[STATUS_FIELD] = 'success'\n",
    "    except ValueError as e:\n",
    "        try:\n",
    "            STATUS_ = e.message\n",
    "        except:\n",
    "            STATUS_ = e.args[0]\n",
    "        return {\n",
    "            STATUS_FIELD: STATUS_\n",
    "        }\n",
    "    time.sleep(0.5)\n",
    "    return get_wikififier_concepts(resp, top_n=4)\n",
    "\n",
    "# Main function to wikify the data\n",
    "def wikify_data(docs, wikifier_key):\n",
    "    \"\"\"Process each text entry independently for annotations\n",
    "\n",
    "    Args:\n",
    "        docs: List of documents, each document is a dict with at least a \"text\" field.\n",
    "        wikifier_key: API key for the Wikifier service.\n",
    "\n",
    "    Returns:\n",
    "        List of dictionaries with annotations embedded.\n",
    "    \"\"\"\n",
    "    enrichments = []\n",
    "    for part in docs:\n",
    "        # Process each text independently\n",
    "        annotations = _wikify(part[\"text\"], wikifier_key, DF_IGNORE_VAL, WORDS_IGNORE_VAL)\n",
    "        part[\"annotations\"] = annotations\n",
    "        enrichments.append(part)\n",
    "\n",
    "    return enrichments\n",
    "\n",
    "# Helper function to extract filename\n",
    "def _get_filename(filepath):\n",
    "    return basename(filepath)\n",
    "\n",
    "# Function to handle file input/output\n",
    "def get_wikifications_from_file(filepath, output_file_dir, wikifier_api_key):\n",
    "    with open(filepath) as infile:\n",
    "        lines = [json.loads(l) for l in infile.readlines() if l != \"\"]\n",
    "\n",
    "    if len(lines) == 0:\n",
    "        return {\"filepath\": filepath, \"status\": \"success: blank file\"}\n",
    "\n",
    "    annotations = list(wikify_data(lines, wikifier_api_key))\n",
    "\n",
    "    filename = _get_filename(filepath)\n",
    "\n",
    "    result_str = \"\\n\".join([json.dumps(anno) for anno in annotations])\n",
    "    with open(output_file_dir + filename, \"w\") as out:\n",
    "        out.write(result_str)\n",
    "\n",
    "    return {\"filepath\": filepath, \"status\": \"success\"}\n",
    "\n",
    "# Main function to run the program\n",
    "def main(input_filepath, output_filepath, wikifier_api_key):\n",
    "    with open(input_filepath, 'r') as infile:\n",
    "        data = json.load(infile)\n",
    "    \n",
    "    enriched_data = wikify_data(data, wikifier_api_key)\n",
    "    \n",
    "    with open(output_filepath, 'w') as outfile:\n",
    "        json.dump(enriched_data, outfile, indent=4)\n",
    "    \n",
    "    print(f\"Wikifier annotations saved to {output_filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_filepath = '/home/qiyu/Dev/ziqing/wiki/ready_squad_question.json'\n",
    "# output_filepath = '/home/qiyu/Dev/ziqing/wiki/wikified_squad_question.json'\n",
    "# wikifier_api_key = 'ffymhmwszzdvzrzxttemhghcofjnwn'\n",
    "# main(input_filepath, output_filepath, wikifier_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_filepath = '/home/qiyu/Dev/ziqing/wiki/ready_khan_question_computing.json'\n",
    "# output_filepath = '/home/qiyu/Dev/ziqing/wiki/wikified_khan_question_computing.json'\n",
    "# wikifier_api_key = 'ffymhmwszzdvzrzxttemhghcofjnwn'\n",
    "# main(input_filepath, output_filepath, wikifier_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_filepath = '/home/qiyu/Dev/ziqing/wiki/tgt_test1.json'\n",
    "# output_filepath = '/home/qiyu/Dev/ziqing/wiki/wikified_tgt_test1.json'\n",
    "# wikifier_api_key = 'ffymhmwszzdvzrzxttemhghcofjnwn'\n",
    "# main(input_filepath, output_filepath, wikifier_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_filepath = '/home/qiyu/Dev/ziqing/wiki/tgt_test2.json'\n",
    "# output_filepath = '/home/qiyu/Dev/ziqing/wiki/wikified_tgt_test2.json'\n",
    "# wikifier_api_key = 'ffymhmwszzdvzrzxttemhghcofjnwn'\n",
    "# main(input_filepath, output_filepath, wikifier_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_filepath = '/home/qiyu/Dev/ziqing/wiki/tgt_test3.json'\n",
    "# output_filepath = '/home/qiyu/Dev/ziqing/wiki/wikified_tgt_test3.json'\n",
    "# wikifier_api_key = 'ffymhmwszzdvzrzxttemhghcofjnwn'\n",
    "# main(input_filepath, output_filepath, wikifier_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_filepath = '/home/qiyu/Dev/ziqing/wiki/src_test1.json'\n",
    "# output_filepath = '/home/qiyu/Dev/ziqing/wiki/wikified_src_test1.json'\n",
    "# wikifier_api_key = 'ffymhmwszzdvzrzxttemhghcofjnwn'\n",
    "# main(input_filepath, output_filepath, wikifier_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_filepath = '/home/qiyu/Dev/ziqing/wiki/src_test2.json'\n",
    "# output_filepath = '/home/qiyu/Dev/ziqing/wiki/wikified_src_test2.json'\n",
    "# wikifier_api_key = 'ffymhmwszzdvzrzxttemhghcofjnwn'\n",
    "# main(input_filepath, output_filepath, wikifier_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_filepath = '/home/qiyu/Dev/ziqing/wiki/src_test3.json'\n",
    "# output_filepath = '/home/qiyu/Dev/ziqing/wiki/wikified_src_test3.json'\n",
    "# wikifier_api_key = 'ffymhmwszzdvzrzxttemhghcofjnwn'\n",
    "# main(input_filepath, output_filepath, wikifier_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_filepath = '/home/qiyu/Dev/ziqing/wiki/KhanQ_question.json'\n",
    "# output_filepath = '/home/qiyu/Dev/ziqing/wiki/wikified_KhanQ_question.json'\n",
    "# wikifier_api_key = 'ffymhmwszzdvzrzxttemhghcofjnwn'\n",
    "# main(input_filepath, output_filepath, wikifier_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_filepath = '/home/qiyu/Dev/ziqing/wiki/KhanQ_text.json'\n",
    "# output_filepath = '/home/qiyu/Dev/ziqing/wiki/wikified_KhanQ_text.json'\n",
    "# wikifier_api_key = 'ffymhmwszzdvzrzxttemhghcofjnwn'\n",
    "# main(input_filepath, output_filepath, wikifier_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_filepath = '/home/qiyu/Dev/ziqing/wiki/eval_squad_question.json'\n",
    "output_filepath = '/home/qiyu/Dev/ziqing/wiki/wikified_eval_squad_question.json'\n",
    "wikifier_api_key = 'ffymhmwszzdvzrzxttemhghcofjnwn'\n",
    "main(input_filepath, output_filepath, wikifier_api_key)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OneBit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
