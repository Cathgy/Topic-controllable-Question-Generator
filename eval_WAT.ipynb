{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MY_GCUBE_TOKEN = 'c7f14730-4c9b-4da5-aec2-d9af2579d505-843339462'\n",
    "\n",
    "class WATAnnotation:\n",
    "    # An entity annotated by WAT\n",
    "\n",
    "    def __init__(self, d, sentence=None, index=None):\n",
    "        \n",
    "        self.sentence = sentence  \n",
    "        self.index = index        \n",
    "        # char offset (included)\n",
    "        self.start = d['start']\n",
    "        # char offset (not included)\n",
    "        self.end = d['end']\n",
    "\n",
    "        # annotation accuracy\n",
    "        self.rho = d['rho']\n",
    "        # spot-entity probability\n",
    "        self.prior_prob = d['explanation']['prior_explanation']['entity_mention_probability']\n",
    "\n",
    "        # annotated text\n",
    "        self.spot = d['spot']\n",
    "\n",
    "        # Wikpedia entity info\n",
    "        self.wiki_id = d['id']\n",
    "        self.wiki_title = d['title']\n",
    "\n",
    "\n",
    "    def json_dict(self):\n",
    "        # Simple dictionary representation\n",
    "        return {'original_sentence': self.sentence, \n",
    "                'sentence_index': self.index,        \n",
    "                'wiki_title': self.wiki_title,\n",
    "                'wiki_id': self.wiki_id,\n",
    "                'start': self.start,\n",
    "                'end': self.end,\n",
    "                'rho': self.rho,\n",
    "                'prior_prob': self.prior_prob\n",
    "                }\n",
    "\n",
    "def wat_entity_linking(text, index):\n",
    "    # Main method, text annotation with WAT entity linking system\n",
    "    wat_url = 'https://wat.d4science.org/wat/tag/tag'\n",
    "    payload = [(\"gcube-token\", MY_GCUBE_TOKEN),\n",
    "               (\"text\", text),\n",
    "               (\"lang\", 'en'),\n",
    "               (\"tokenizer\", \"nlp4j\"),\n",
    "               ('debug', 9),\n",
    "               (\"method\",\n",
    "                \"spotter:includeUserHint=true:includeNamedEntity=true:includeNounPhrase=true,prior:k=50,filter-valid,centroid:rescore=true,topk:k=5,voting:relatedness=lm,ranker:model=0046.model,confidence:model=pruner-wiki.linear\")]\n",
    "\n",
    "    response = requests.get(wat_url, params=payload)\n",
    "    if response.status_code == 200:\n",
    "        json_response = response.json()\n",
    "        if 'annotations' in json_response:\n",
    "            return [WATAnnotation(a, sentence=text, index=index).json_dict() for a in json_response['annotations']]\n",
    "        else:\n",
    "            print(\"No annotations found for this sentence.\")\n",
    "            return []\n",
    "    else:\n",
    "        print(\"Failed to fetch data:\", response.status_code)\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####annotation of generated questions\n",
    "# reference.npy\n",
    "\n",
    "predict_sentences = np.load('/home/qiyu/Dev/ziqing/T5/train/eval_squad_once/predictionstopic2_T5_squad_once.npy')\n",
    "#predict_sentences = np.load('/home/qiyu/Dev/ziqing/T5/train/eval_squad_once/predictions_T5_squad_once.npy')\n",
    "annotations = []\n",
    "for idx, sentence in enumerate(predict_sentences):\n",
    "    sentence_annotations = wat_entity_linking(sentence, idx)\n",
    "    if sentence_annotations:\n",
    "        annotations.append(sentence_annotations)\n",
    "    else:\n",
    "        print(f\"No annotations for sentence {idx}: {sentence}\")\n",
    "        \n",
    "# Assuming `annotations` is already populated as shown in previous parts\n",
    "# Flatten the annotations list if necessary (since annotations may be lists of lists)\n",
    "flattened_annotations = [item for sublist in annotations for item in sublist]\n",
    "\n",
    "# Define the output file path\n",
    "\n",
    "annotation_predict_path = '/home/qiyu/Dev/ziqing/T5/train/eval_squad_once/TOPIC_w2v/annotation_otherpredict.json'\n",
    "#annotation_predict_path = '/home/qiyu/Dev/ziqing/T5/train/eval_squad_once/TOPIC_w2v/annotation_labelpredict.json'\n",
    "\n",
    "# Write the annotations to a JSON file with the specified structure\n",
    "try:\n",
    "    with open(annotation_predict_path, 'w', encoding='utf-8') as file:\n",
    "        json.dump(flattened_annotations, file, ensure_ascii=False, indent=4)\n",
    "    print(\"All annotations have been processed and saved successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while writing to the file: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####KhanQ.csv topic id（annotation）\n",
    "# Step 2: Load data from CSV file\n",
    "df = pd.read_csv('/home/qiyu/Dev/ziqing/T5/combined_KhanQ.csv')\n",
    "topics = df['topic']\n",
    "\n",
    "# Step 3: Process topics with entity linking\n",
    "annotations = []\n",
    "for idx, topic in tqdm(enumerate(topics), total=len(topics), desc=\"Processing Topics\"):\n",
    "    if pd.notna(topic):  # Only process if the topic is not NA\n",
    "        topic_annotations = wat_entity_linking(topic, idx)\n",
    "        annotations.append(topic_annotations)\n",
    "    else:\n",
    "        print(f\"Skipping NA topic at index {idx}\")\n",
    "        \n",
    "# Step 4: Save annotations to a new file\n",
    "annotation_reference_path = '/home/qiyu/Dev/ziqing/T5/train/annotation_referencetopic_combinedKhanQ.json'\n",
    "try:\n",
    "    with open(annotation_reference_path, 'w', encoding='utf-8') as file:\n",
    "        json.dump(annotations, file, ensure_ascii=False, indent=4)\n",
    "    print(\"All topics have been processed and annotations have been saved successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while writing to the file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_reference_path = '/home/qiyu/Dev/ziqing/T5/train/annotation_referencetopic_combinedKhanQ.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_relatedness(token, ids, relatedness='jaccard'):\n",
    "    base_url = 'https://wat.d4science.org/wat/relatedness/graph'\n",
    "    params = {\n",
    "        'gcube-token': token,\n",
    "        'lang': 'en',\n",
    "        'ids': ids,\n",
    "        'relatedness': relatedness\n",
    "    }\n",
    "    response = requests.get(base_url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return response.text\n",
    "    \n",
    "def default_converter(o):\n",
    "    if isinstance(o, np.integer):\n",
    "        return int(o)\n",
    "    elif isinstance(o, np.floating):\n",
    "        return float(o)\n",
    "    elif isinstance(o, np.ndarray):\n",
    "        return o.tolist()\n",
    "    else:\n",
    "        raise TypeError(f\"Object of type '{type(o).__name__}' is not JSON serializable\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##relatedness after annotation\n",
    "# Step 2: Load JSON data from files\n",
    "with open(annotation_predict_path, 'r', encoding='utf-8') as file:\n",
    "    predict_data = json.load(file)\n",
    "\n",
    "predict_df = pd.DataFrame(predict_data)\n",
    "\n",
    "with open(annotation_reference_path, 'r', encoding='utf-8') as file:\n",
    "    reference_data = json.load(file)\n",
    "\n",
    "\n",
    "flattened_reference_data = [item for sublist in reference_data for item in sublist]\n",
    "reference_df = pd.DataFrame(flattened_reference_data)\n",
    "\n",
    "\n",
    "print(predict_df.head())\n",
    "print(reference_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_GCUBE_TOKEN = 'c7f14730-4c9b-4da5-aec2-d9af2579d505-843339462'\n",
    "\n",
    "# Step 3: Process each sentence index from annotation_predict.json\n",
    "results = []\n",
    "for index in predict_df['sentence_index'].unique():\n",
    "    # Find matching reference data\n",
    "    ref_entry = reference_df[reference_df['sentence_index'] == index]\n",
    "    if not ref_entry.empty:\n",
    "        # Collect all wiki_ids from both datasets for the current index\n",
    "        pred_ids = predict_df[predict_df['sentence_index'] == index]['wiki_id'].tolist()\n",
    "        ref_ids = ref_entry['wiki_id'].tolist()\n",
    "        entity_ids = pred_ids + ref_ids\n",
    "\n",
    "        # Compute relatedness\n",
    "        relatedness_result = compute_relatedness(MY_GCUBE_TOKEN, entity_ids)\n",
    "        results.append({\n",
    "            'sentence_index': index,\n",
    "            'relatedness_result': relatedness_result\n",
    "        })\n",
    "    \n",
    "#original_relatedness_path = '/home/qiyu/Dev/ziqing/T5/train/eval_squad_once/TOPIC_w2v/original_relate_labeltopic.json'\n",
    "original_relatedness_path = '/home/qiyu/Dev/ziqing/T5/train/eval_squad_once/TOPIC_w2v/original_relate_othertopic.json'\n",
    "\n",
    "\n",
    "with open(original_relatedness_path, 'w', encoding='utf-8') as file:\n",
    "    json.dump(results, file, indent=4, default=default_converter)\n",
    "\n",
    "print(\"Results have been successfully saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_max_relatedness(input_path):\n",
    "    with open(input_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    results = []\n",
    "    for item in data:\n",
    "        max_relatedness = max(pair['relatedness'] for pair in item['relatedness_result']['pairs']) if item['relatedness_result']['pairs'] else 1\n",
    "        results.append({\n",
    "            \"sentence_index\": item['sentence_index'],\n",
    "            \"relation\": item['relatedness_result']['relation'],\n",
    "            \"relatedness_score\": max_relatedness\n",
    "        })\n",
    "    return results\n",
    "\n",
    "\n",
    "def update_and_save_scores(predict_df, reference_df, results, output_path):\n",
    "\n",
    "    scores_df = pd.DataFrame(results)\n",
    "\n",
    "    for index, group in predict_df.groupby('sentence_index'):\n",
    "        ref_group = reference_df[reference_df['sentence_index'] == index]\n",
    "        if set(group['wiki_id']).intersection(set(ref_group['wiki_id'])):\n",
    "            scores_df.loc[scores_df['sentence_index'] == index, 'relatedness_score'] = 1\n",
    "\n",
    "    scores_df.to_json(output_path, orient='records', lines=False, force_ascii=False, indent=4)\n",
    "    print(f\"Updated scores have been successfully saved to '{output_path}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_max = select_max_relatedness(original_relatedness_path)\n",
    "#final_output_path = '/home/qiyu/Dev/ziqing/T5/train/eval_squad_once/TOPIC_w2v/relate_labeltopic.json'\n",
    "final_output_path = '/home/qiyu/Dev/ziqing/T5/train/eval_squad_once/TOPIC_w2v/relate_othertopic.json'\n",
    "\n",
    "update_and_save_scores(predict_df, reference_df, select_max, final_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results_to_file(results, file_path):\n",
    "    \"\"\"\n",
    "    Save the results to a specified text file.\n",
    "    \n",
    "    Parameters:\n",
    "        results (list): List of strings containing the results to be written to the file.\n",
    "        file_path (str): Path to the file where results will be saved.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        for result in results:\n",
    "            file.write(result + \"\\n\")\n",
    "\n",
    "def calculate_and_report_relatedness(file_path):\n",
    "    \"\"\"\n",
    "    Load score data, perform analysis, and report the relatedness scores.\n",
    "    \n",
    "    Parameters:\n",
    "        file_path (str): Path to the JSON file containing score data.\n",
    "    \"\"\"\n",
    "    # Load JSON data from the file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        score_data = json.load(file)\n",
    "\n",
    "    # Convert the loaded JSON data to a pandas DataFrame\n",
    "    score_df = pd.DataFrame(score_data)\n",
    "\n",
    "    # Calculate the average relatedness score for all entries\n",
    "    average_relatedness_score = score_df['relatedness_score'].mean()\n",
    "    average_score_str = f\"Average Relatedness Score: {average_relatedness_score}\"\n",
    "\n",
    "    # Filter and calculate the average score for entries with 'relatedness_score' >= 0.01\n",
    "    filtered_score_df = score_df[score_df['relatedness_score'] >= 0.01]\n",
    "    average_relatedness_score_con = filtered_score_df['relatedness_score'].mean()\n",
    "    average_score_con_str = f\"Average Relatedness Score (Con): {average_relatedness_score_con}\"\n",
    "\n",
    "    # Calculate the number of entries with a relatedness score of exactly 1.0\n",
    "    count_score_one = score_df[score_df['relatedness_score'] == 1.0].shape[0]\n",
    "\n",
    "    # Calculate the total number of entries and the percentage of entries with a score of 1.0\n",
    "    total_count = score_df.shape[0]\n",
    "    percentage = (count_score_one / total_count) * 100\n",
    "    percentage_str = f\"Percentage of 'relatedness_score' equal to 1.0: {percentage:.2f}%\"\n",
    "\n",
    "    # Save results to text file\n",
    "    results = [average_score_str, average_score_con_str, percentage_str]\n",
    "    \n",
    "    #output_text_path = '/home/qiyu/Dev/ziqing/T5/train/eval_squad_once/TOPIC_w2v/relatedness_labeltopic.txt'\n",
    "    output_text_path = '/home/qiyu/Dev/ziqing/T5/train/eval_squad_once/TOPIC_w2v/relatedness_othertopic.txt'\n",
    "\n",
    "    save_results_to_file(results, output_text_path)\n",
    "    print(f\"Results have been successfully saved to '{output_text_path}'.\")\n",
    "\n",
    "#final_output_path= '/home/qiyu/Dev/ziqing/T5/train/eval_squad_once/TOPIC_w2v/relate_labeltopic.json'\n",
    "final_output_path= '/home/qiyu/Dev/ziqing/T5/train/eval_squad_once/TOPIC_w2v/relate_othertopic.json'\n",
    "\n",
    "calculate_and_report_relatedness(final_output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OneBit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
